{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ff1120",
   "metadata": {},
   "source": [
    "# SpaceX Falcon 9 First Stage Landing Prediction - Web Scraping\n",
    "\n",
    "## Project Overview\n",
    "This notebook collects SpaceX Falcon 9 launch data through web scraping from Wikipedia. Unlike API-based collection, web scraping allows us to extract structured data from HTML tables, providing historical launch information that complements our dataset for predicting first stage landing success.\n",
    "\n",
    "## Table of Contents\n",
    "1. Import Libraries and Define Helper Functions\n",
    "2. Web Scraping Setup and Data Extraction\n",
    "3. Parse HTML Tables and Extract Launch Records\n",
    "4. Create DataFrame and Export Data\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import Libraries and Define Helper Functions\n",
    "\n",
    "### Import Required Libraries\n",
    "We'll use BeautifulSoup for HTML parsing, requests for web requests, and pandas for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system utilities\n",
    "import sys\n",
    "\n",
    "# Import web scraping libraries\n",
    "import requests  # For making HTTP requests\n",
    "from bs4 import BeautifulSoup  # For parsing HTML content\n",
    "import re  # For regular expressions\n",
    "import unicodedata  # For Unicode string normalization\n",
    "\n",
    "# Import data manipulation library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf1b9a",
   "metadata": {},
   "source": [
    "### Helper Function: Extract Date and Time\n",
    "This function parses date and time information from table cells, returning them as a clean list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(table_cells):\n",
    "    \"\"\"\n",
    "    Extract date and time from table cell strings.\n",
    "    \n",
    "    Args:\n",
    "        table_cells: BeautifulSoup table cell containing date and time data\n",
    "    \n",
    "    Returns:\n",
    "        list: First two elements containing date and time strings\n",
    "    \"\"\"\n",
    "    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563a803d",
   "metadata": {},
   "source": [
    "### Helper Function: Extract Booster Version\n",
    "Extracts and formats the booster version information from table cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def booster_version(table_cells):\n",
    "    \"\"\"\n",
    "    Extract booster version by joining every other string element.\n",
    "    \n",
    "    Args:\n",
    "        table_cells: BeautifulSoup table cell containing booster version data\n",
    "    \n",
    "    Returns:\n",
    "        str: Cleaned booster version string\n",
    "    \"\"\"\n",
    "    # Join every even-indexed string (skipping odd indices) and exclude the last element\n",
    "    out = ''.join([booster_version for i, booster_version in enumerate(table_cells.strings) if i % 2 == 0][0:-1])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402a0294",
   "metadata": {},
   "source": [
    "### Helper Function: Extract Landing Status\n",
    "Retrieves the landing status text from table cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landing_status(table_cells):\n",
    "    \"\"\"\n",
    "    Extract the first string from table cells representing landing status.\n",
    "    \n",
    "    Args:\n",
    "        table_cells: BeautifulSoup table cell containing landing status\n",
    "    \n",
    "    Returns:\n",
    "        str: Landing status string\n",
    "    \"\"\"\n",
    "    out = [i for i in table_cells.strings][0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc90eea",
   "metadata": {},
   "source": [
    "### Helper Function: Extract Payload Mass\n",
    "Parses and normalizes payload mass data, extracting the kilogram value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af0a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass(table_cells):\n",
    "    \"\"\"\n",
    "    Extract and normalize payload mass from table cells.\n",
    "    \n",
    "    Args:\n",
    "        table_cells: BeautifulSoup table cell containing mass data\n",
    "    \n",
    "    Returns:\n",
    "        str or int: Mass value with 'kg' unit, or 0 if not found\n",
    "    \"\"\"\n",
    "    # Normalize Unicode characters to standard format\n",
    "    mass = unicodedata.normalize(\"NFKD\", table_cells.text).strip()\n",
    "    \n",
    "    if mass:\n",
    "        # Find the position of 'kg' and extract everything up to and including it\n",
    "        mass.find(\"kg\")\n",
    "        new_mass = mass[0:mass.find(\"kg\") + 2]\n",
    "    else:\n",
    "        new_mass = 0\n",
    "    \n",
    "    return new_mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db0572e",
   "metadata": {},
   "source": [
    "### Helper Function: Extract Column Names from Headers\n",
    "Cleans and extracts column names from HTML table headers by removing unwanted tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_column_from_header(row):\n",
    "    \"\"\"\n",
    "    Clean and extract column name from HTML table header row.\n",
    "    Removes br, a, and sup tags, then returns the cleaned text.\n",
    "    \n",
    "    Args:\n",
    "        row: BeautifulSoup row element from table header\n",
    "    \n",
    "    Returns:\n",
    "        str or None: Cleaned column name, or None if invalid\n",
    "    \"\"\"\n",
    "    # Remove line break tags\n",
    "    if (row.br):\n",
    "        row.br.extract()\n",
    "    \n",
    "    # Remove anchor (link) tags\n",
    "    if row.a:\n",
    "        row.a.extract()\n",
    "    \n",
    "    # Remove superscript tags\n",
    "    if row.sup:\n",
    "        row.sup.extract()\n",
    "    \n",
    "    # Join all remaining content into column name\n",
    "    colunm_name = ' '.join(row.contents)\n",
    "    \n",
    "    # Filter out digit-only names and return cleaned name\n",
    "    if not(colunm_name.strip().isdigit()):\n",
    "        colunm_name = colunm_name.strip()\n",
    "        return colunm_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c23dd1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Web Scraping Setup and Data Extraction\n",
    "\n",
    "### Configure Wikipedia URL and Headers\n",
    "We'll scrape the Wikipedia page containing Falcon 9 and Falcon Heavy launch records. Custom headers are used to mimic a browser request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52001207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the static Wikipedia URL containing SpaceX launch data\n",
    "# This is a specific revision to ensure data consistency\n",
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\"\n",
    "\n",
    "# Set up headers to mimic a browser request (some websites block requests without proper headers)\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75897cd1",
   "metadata": {},
   "source": [
    "### Request and Parse HTML Content\n",
    "Make an HTTP GET request to fetch the webpage and parse it using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send GET request to the Wikipedia page\n",
    "response = requests.get(static_url, headers=headers)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup with the html.parser\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d2eb8",
   "metadata": {},
   "source": [
    "### Extract All HTML Tables\n",
    "Find all table elements in the parsed HTML. The launch data is contained within these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use find_all to locate all table elements in the HTML\n",
    "html_tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35177757",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Parse HTML Tables and Extract Launch Records\n",
    "\n",
    "### Extract Column Names from Table Headers\n",
    "Iterate through the table headers to extract clean column names for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82f309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flight No.', 'Date and time ( )', 'Launch site', 'Payload', 'Payload mass', 'Orbit', 'Customer', 'Launch outcome']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store column names\n",
    "column_names = []\n",
    "\n",
    "# Access the third table (index 2) which contains the launch data\n",
    "# Find all table header (th) elements\n",
    "for row in html_tables[2].find_all('th'):\n",
    "    # Apply our helper function to clean and extract the column name\n",
    "    name = extract_column_from_header(row)\n",
    "    \n",
    "    # Only append non-empty column names\n",
    "    if name is not None and len(name) > 0:\n",
    "        column_names.append(name)\n",
    "\n",
    "# Display the extracted column names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd4029",
   "metadata": {},
   "source": [
    "### Initialize Data Dictionary\n",
    "Create a dictionary structure to store all launch data, with each column initialized as an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebfbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with keys from column_names, all values initially None\n",
    "launch_dict = dict.fromkeys(column_names)\n",
    "\n",
    "# Remove an irrelevant column that we don't need\n",
    "del launch_dict['Date and time ( )']\n",
    "\n",
    "# Initialize each column as an empty list to store data\n",
    "launch_dict['Flight No.'] = []\n",
    "launch_dict['Launch site'] = []\n",
    "launch_dict['Payload'] = []\n",
    "launch_dict['Payload mass'] = []\n",
    "launch_dict['Orbit'] = []\n",
    "launch_dict['Customer'] = []\n",
    "launch_dict['Launch outcome'] = []\n",
    "\n",
    "# Add additional columns for our analysis\n",
    "launch_dict['Version Booster'] = []\n",
    "launch_dict['Booster landing'] = []\n",
    "launch_dict['Date'] = []\n",
    "launch_dict['Time'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c82f1f",
   "metadata": {},
   "source": [
    "### Parse Launch Tables and Extract Data\n",
    "This is the core scraping logic that iterates through all launch tables, extracts data from each row, and populates our dictionary with launch information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05f7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F9 v1.07B0003.18\n",
      "F9 v1.07B0004.18\n",
      "F9 v1.07B0005.18\n",
      "F9 v1.07B0006.18\n",
      "F9 v1.07B0007.18\n",
      "F9 v1.17B10038\n",
      "F9 v1.1\n",
      "F9 v1.1\n",
      "F9 v1.1\n",
      "F9 v1.1\n",
      "F9 v1.1\n",
      "F9 v1.1[\n",
      "F9 v1.1[\n",
      "F9 v1.1[\n",
      "F9 v1.1[\n",
      "F9 v1.1[\n",
      "F9 v1.1[\n",
      "F9 v1.1[\n",
      "F9 v1.1[\n",
      "F9 FT[\n",
      "F9 v1.1[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT♺[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 FTB1029.2195\n",
      "F9 FT[\n",
      "F9 FT[\n",
      "F9 B4[\n",
      "F9 FT[\n",
      "F9 B4[\n",
      "F9 B4[\n",
      "F9 FTB1031.2220\n",
      "F9 B4[\n",
      "F9 FTB1035.2227\n",
      "F9 FTB1036.2227\n",
      "F9 B4[\n",
      "F9 FTB1032.2245\n",
      "F9 FTB1038.2268\n",
      "F9 B4[\n",
      "F9 B4B1041.2268\n",
      "F9 B4B1039.2292\n",
      "F9 B4[\n",
      "F9 B5311B1046.1268\n",
      "F9 B4B1043.2322\n",
      "F9 B4B1040.2268\n",
      "F9 B4B1045.2336\n",
      "F9 B5\n",
      "F9 B5349B1048[\n",
      "F9 B5B1046.2354\n",
      "F9 B5[\n",
      "F9 B5B1048.2364\n",
      "F9 B5B1047.2268\n",
      "F9 B5B1046.3268\n",
      "F9 B5[\n",
      "F9 B5[\n",
      "F9 B5B1049.2397\n",
      "F9 B5B1048.3399\n",
      "F9 B5[]413\n",
      "F9 B5[\n",
      "F9 B5B1049.3434\n",
      "F9 B5B1051.2420\n",
      "F9 B5B1056.2465\n",
      "F9 B5B1047.3472\n",
      "F9 B5\n",
      "F9 B5[\n",
      "F9 B5B1056.3482\n",
      "F9 B5\n",
      "F9 B5\n",
      "F9 B5\n",
      "F9 B5\n",
      "F9 B5\n",
      "F9 B5\n",
      "F9 B5\n",
      "F9 B5[\n",
      "F9 B5\n",
      "F9 B5\n",
      "F9 B5\n",
      "F9 B5B1058.2544\n",
      "F9 B5\n",
      "F9 B5B1049.6544\n",
      "F9 B5\n",
      "F9 B5B1060.2563\n",
      "F9 B5B1058.3565\n",
      "F9 B5B1051.6568\n",
      "F9 B5\n",
      "F9 B5\n",
      "F9 B5[\n",
      "F9 B5\n",
      "F9 B5 ♺[\n",
      "F9 B5 ♺[\n",
      "F9 B5 ♺\n",
      "F9 B5 ♺\n",
      "F9 B5\n",
      "F9 B5B1051.8609\n",
      "F9 B5B1058.5613\n",
      "F9 B5 ♺[\n",
      "F9 B5 ♺\n",
      "F9 B5 ♺[\n",
      "F9 B5 ♺[\n",
      "F9 B5 ♺\n",
      "F9 B5B1060.6643\n",
      "F9 B5 ♺\n",
      "F9 B5B1061.2647\n",
      "F9 B5B1060.7652\n",
      "F9 B5B1049.9655\n",
      "F9 B5B1051.10657\n",
      "F9 B5B1058.8660\n",
      "F9 B5B1063.2665\n",
      "F9 B5B1067.1668\n",
      "F9 B5\n"
     ]
    }
   ],
   "source": [
    "# Track the number of successfully extracted rows\n",
    "extracted_row = 0\n",
    "\n",
    "# Iterate through each table with class \"wikitable plainrowheaders collapsible\"\n",
    "for table_number, table in enumerate(soup.find_all('table', \"wikitable plainrowheaders collapsible\")):\n",
    "    \n",
    "    # Iterate through each row in the current table\n",
    "    for rows in table.find_all(\"tr\"):\n",
    "        \n",
    "        # Check if the first cell is a table heading (th) with a flight number\n",
    "        if rows.th:\n",
    "            if rows.th.string:\n",
    "                flight_number = rows.th.string.strip()\n",
    "                # Verify if it's a numeric flight number\n",
    "                flag = flight_number.isdigit()\n",
    "        else:\n",
    "            flag = False\n",
    "        \n",
    "        # Extract all table data cells (td) from the row\n",
    "        row = rows.find_all('td')\n",
    "        \n",
    "        # Process the row only if it contains a valid flight number\n",
    "        if flag:\n",
    "            extracted_row += 1\n",
    "            \n",
    "            # Extract date and time\n",
    "            datatimelist = date_time(row[0])\n",
    "            \n",
    "            # Extract and clean date (remove trailing comma)\n",
    "            date = datatimelist[0].strip(',')\n",
    "            \n",
    "            # Extract time\n",
    "            time = datatimelist[1]\n",
    "            \n",
    "            # Extract booster version\n",
    "            bv = booster_version(row[1])\n",
    "            # If booster version is empty, try to get it from the anchor tag\n",
    "            if not(bv):\n",
    "                bv = row[1].a.string\n",
    "            print(bv)\n",
    "            \n",
    "            # Extract launch site name from anchor tag\n",
    "            launch_site = row[2].a.string if row[2].a else None\n",
    "            \n",
    "            # Extract payload name from anchor tag\n",
    "            payload = row[3].a.string if row[3].a else None\n",
    "            \n",
    "            # Extract and normalize payload mass\n",
    "            payload_mass = get_mass(row[4])\n",
    "            \n",
    "            # Extract target orbit from anchor tag\n",
    "            orbit = row[5].a.string if row[5].a else None\n",
    "            \n",
    "            # Extract customer name from anchor tag\n",
    "            customer = row[6].a.string if row[6].a else None\n",
    "            \n",
    "            # Extract launch outcome (first string in the cell)\n",
    "            launch_outcome = list(row[7].strings)[0]\n",
    "            \n",
    "            # Extract booster landing status\n",
    "            booster_landing = landing_status(row[8])\n",
    "            \n",
    "            # Append all extracted data to the launch dictionary\n",
    "            launch_dict['Flight No.'].append(flight_number)\n",
    "            launch_dict['Date'].append(date)\n",
    "            launch_dict['Time'].append(time)\n",
    "            launch_dict['Version Booster'].append(bv)\n",
    "            launch_dict['Launch site'].append(launch_site)\n",
    "            launch_dict['Payload'].append(payload)\n",
    "            launch_dict['Payload mass'].append(payload_mass)\n",
    "            launch_dict['Orbit'].append(orbit)\n",
    "            launch_dict['Customer'].append(customer)\n",
    "            launch_dict['Launch outcome'].append(launch_outcome)\n",
    "            launch_dict['Booster landing'].append(booster_landing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b8f3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Create DataFrame and Export Data\n",
    "\n",
    "### Convert Dictionary to DataFrame\n",
    "Transform the populated dictionary into a pandas DataFrame for analysis and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab60827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from the launch_dict, converting each list to a pandas Series\n",
    "df = pd.DataFrame({key: pd.Series(value) for key, value in launch_dict.items()})\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(f\"Total launches scraped: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14f306",
   "metadata": {},
   "source": [
    "### Export to CSV\n",
    "Save the scraped dataset to a CSV file for future analysis and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77bc4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('spacex_web_scraped_data.csv', index=False)\n",
    "print(\"✓ Data successfully saved to 'spacex_web_scraped_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4cfcb1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Data Collection Complete\n",
    "We successfully scraped SpaceX Falcon 9 launch data from Wikipedia, extracting the following information:\n",
    "\n",
    "**Key Features Collected:**\n",
    "- Flight number and launch date/time\n",
    "- Booster version details\n",
    "- Launch site locations\n",
    "- Payload information and mass\n",
    "- Target orbits\n",
    "- Customer details\n",
    "- Launch outcomes\n",
    "- Booster landing status\n",
    "\n",
    "The scraped data has been saved to `spacex_web_scraped_data.csv` and is ready for further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
